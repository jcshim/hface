# Raspberry Pi 5와 Hailo-8 기반 실시간 얼굴 인식 시스템 아키텍처

## 시스템 개요 (Overview)  
라즈베리 파이 5에 Hailo-8 AI 가속기를 결합한 실시간 얼굴 인식 시스템은 **엣지(Edge) 디바이스** 상에서 영상 스트림을 받아 사람의 얼굴을 인식하는 파이프라인으로 구성됩니다. 카메라로부터 영상 프레임을 입력받아 **GStreamer** 기반 파이프라인으로 처리하고, **Hailo TAPPAS** 프레임워크를 통해 **얼굴 검출** 및 **얼굴 인식**과 같은 딥러닝 모델 추론을 Hailo-8 칩에서 가속합니다. 시스템은 검출된 얼굴 영역을 정렬(얼굴 각도 보정)한 뒤 임베딩 벡터를 추출하여 **DB의 얼굴 특성과 비교**함으로써 누구의 얼굴인지 식별하고, 그 결과를 실시간으로 출력합니다. 이러한 모든 단계가 라즈베리 파이 5의 호스트 프로세서(ARM CPU)와 Hailo-8 AI 가속기 사이의 협업으로 이루어지며, 클라우드 서버에 의존하지 않고 디바이스 내부에서 실시간으로 처리됩니다. 

 ([image]()) **그림 1:** Raspberry Pi 5 + Hailo-8 기반 얼굴 인식 파이프라인 개념도. 카메라 영상이 입력되어 GStreamer 파이프라인을 통해 전처리된 후, Hailo-8에서 **TAPPAS** 딥러닝 모델로 얼굴 검출과 임베딩 추출을 수행한다. 검출된 얼굴에 대한 **얼굴 정렬** 및 **임베딩 기반 매칭**을 거쳐 최종 인식 결과(예: 신원 or Unknown)를 출력한다.

## 주요 모듈 구성 및 역할 (Module Descriptions)  

### 1. 카메라 입력 (Camera Input)  
**카메라 입력 모듈**은 실시간 영상 프레임을 캡처하는 역할을 합니다. Raspberry Pi 5에 연결된 카메라 (예: Pi Camera 모듈 또는 USB 웹캠)를 통해 **연속적인 영상 스트림**을 획득하며, 일반적으로 30 FPS 이상의 프레임 속도와 720p~1080p 해상도로 동작합니다. 카메라는 **V4L2(Video4Linux2)** 드라이버 등을 통해 시스템에 프레임을 공급하며, 이후 단계에서 처리가 용이하도록 **YUV** 또는 **RGB** 포맷으로 영상을 제공합니다. 이 모듈은 GStreamer 파이프라인의 시작 지점으로서 원시 영상 데이터 소스 역할을 하며, 안정적인 프레임 공급과 타임스탬프(sync) 관리 등을 담당합니다.

### 2. GStreamer 파이프라인 (Video Pipeline)  
**GStreamer**는 리눅스에서 널리 쓰이는 오픈소스 **멀티미디어 스트리밍 프레임워크**로, 카메라 입력부터 영상 처리, 출력까지의 과정을 하나의 파이프라인으로 연결해 줍니다 ([GStreamer - Wikipedia](https://en.wikipedia.org/wiki/GStreamer#:~:text=GStreamer%20is%20a%20pipeline,The%20formats%20and%20processes)). 이 시스템에서는 GStreamer를 활용하여 **카메라 → 전처리 → 추론 → 출력**의 복잡한 워크플로우를 구성합니다. 예를 들어, GStreamer 파이프라인은 `v4l2src` 요소로 카메라 **캡처**를 받고, `videoconvert`나 `videoscale` 필터로 **영상 포맷 변환 및 해상도 조정**을 수행하며, Hailo-8 추론 전에 프레임을 딥러닝 모델이 요구하는 크기(예: 640×480 등)로 리사이즈합니다. TAPPAS 프레임워크는 GStreamer와의 **표준 통합**을 지원하므로, 파이프라인 내에 Hailo 추론을 수행하는 커스텀 요소(예: Hailo GStreamer 플러그인 또는 앱 싱크(AppSink) 연계를 통한 Hailo API 호출)를 삽입할 수 있습니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Explorer%20offers%20an%20interactive%20interface,models%20from%20Hailo%E2%80%99s%20vast%20library)). 이를 통해 각 프레임이 **스트리밍 과정에서 곧바로 Hailo-8으로 전달**되어 지연을 최소화하고, 프레임 드롭 없이 실시간 처리가 가능하도록 합니다. 

### 3. 얼굴 검출 (Face Detection – TAPPAS 모델)  
**얼굴 검출 모듈**은 입력 영상에서 사람의 얼굴 영역을 찾아내는 딥러닝 모델로 구성됩니다. Hailo의 **TAPPAS** 소프트웨어 스택에는 엣지 디바이스에서 최적화된 **사전 학습(face detection)** 모델이 포함되어 있으며 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Hailo%20has%20developed%20TAPPAS%20to,friendly)), WIDER Face와 같은 대규모 데이터셋으로 학습된 **신경망 기반 얼굴 검출기**를 사용합니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Facial%20detection%20is%20a%20common,orientation%2C%20structure%20and%20so%20on)). 이 모델은 Hailo-8 가속기에서 실행되어 높은 FPS로 동작하며, 각 프레임에 대해 하나 또는 다수의 얼굴 **바운딩 박스(矩形 영역)**와 신뢰도(confidence score)를 출력합니다. 추론 과정은 Hailo-8 상의 **NN 코어**에서 HailoRT 런타임를 통해 실행되어 호스트 CPU의 부하를 줄이고, 수 밀리초 수준의 지연으로 얼굴 위치를 산출합니다. 예를 들어, 1080p 프레임이 들어오면 내부적으로 300×300이나 640×480 등 모델 입력 크기로 리사이즈되어 Hailo-8에서 처리되고, 결과로 얼굴 영역 좌표들을 반환합니다. 얼굴 검출 결과는 후속 단계인 얼굴 정렬 및 인식 모듈에 전달됩니다.

> **참고:** TAPPAS는 **전체 애플리케이션 예제**들과 미리 훈련된 AI 모델 파이프라인을 제공하는 Hailo의 레퍼런스 소프트웨어 패키지로서, 엣지 AI 개발을 단순화해 줍니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Hailo)). 얼굴 검출 모델 역시 TAPPAS의 예제 중 하나로 제공되며, 개발자는 이를 활용해 Raspberry Pi에서 바로 실행 가능한 최적화된 추론 파이프라인을 얻을 수 있습니다.

### 4. 얼굴 정렬 (Face Alignment)  
얼굴 검출 단계에서 얻은 얼굴 **ROI(Region of Interest)**를 기반으로, **얼굴 정렬(Face Alignment)** 단계를 수행합니다. 이 모듈의 목적은 각기 다른 각도나 위치로 찍힌 얼굴 영상을 정규화하여, 이후 인식 모델이 일관된 입력을 받도록 하는 것입니다. 구체적으로, 검출된 얼굴 영역에 대해 **얼굴의 주요 랜드마크(landmarks)**를 계산합니다. 랜드마크는 눈의 중심, 코 끝, 입꼬리 등 얼굴의 특정 점들을 의미하며, TAPPAS 예제에서는 검출된 얼굴을 잘라낸 후 **두 번째 신경망을 통해 다섯 개의 랜드마크 좌표를 추정**합니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Facial%20detection%20is%20a%20common,orientation%2C%20structure%20and%20so%20on)). Hailo-8 상에서 소형 랜드마크 검출 모델을 돌려 각 얼굴의 특징 점을 얻거나, 혹은 CPU에서 OpenCV의 얼굴 랜드마크 추정기를 사용할 수도 있습니다. 이렇게 얻은 랜드마크 정보를 활용해 **얼굴을 수평 정렬 및 정규화**합니다. 예를 들어 두 눈이 수평선상에 오도록 회전하고, 눈 사이 간격이나 얼굴 크기를 일정하게 맞추기 위해 이미지를 확대/축소하는 **아핀 변환**을 적용합니다. 그 결과 출력되는 정렬된 얼굴 이미지 패치는 얼굴 인식 모듈의 입력으로 사용됩니다. 얼굴 정렬 과정을 거침으로써, 기울어지거나 회전된 얼굴이라도 인식 모델이 높은 정확도로 임베딩을 추출할 수 있게 됩니다.

### 5. 얼굴 인식 임베딩 추출 (Face Recognition Embedding)  
**얼굴 인식 모듈**은 정렬된 얼굴 이미지를 받아 해당 얼굴의 **특징 임베딩 벡터(embedding)**를 생성하는 딥러닝 모델로 구성됩니다. 이 모델 역시 Hailo-8 위에서 구동되며, 사람마다 고유한 **특징 표현(feature representation)**을 산출하도록 사전에 학습되어 있습니다. 일반적으로 **FaceNet, ArcFace** 등으로 알려진 아키텍처와 유사한 컨볼루션 신경망이 사용되며, 학습시 다수 인물의 얼굴 데이터셋(MS-Celeb-1M, VGGFace2 등)을 통해 각 얼굴을 구분짓는 임베딩을 학습합니다. 추론 입력은 보통 112×112 또는 224×224 크기의 정렬된 얼굴 이미지이고, 출력은 예컨대 **128차원 또는 512차원**짜리 실수 벡터입니다. 이 벡터는 입력 얼굴의 지문과 같은 **고유한 표현**으로, 같은 사람이라면 유사한 벡터가, 다른 사람이라면 거리(distance)가 멀어진 벡터가 나오도록 설계됩니다. Hailo-8은 이러한 신경망 연산을 실시간으로 가속하여 여러 얼굴에 대해서도 빠르게 임베딩을 추출할 수 있습니다. 예를 들어 한 프레임에 5명의 얼굴이 있다면, 얼굴 당 임베딩 추출을 수밀리초 수준에 완료하여 전체 프레임 처리를 30 FPS 이상으로 유지할 수 있습니다. 생성된 임베딩 벡터들은 CPU 메모리로 전달되어 **후속 유사도 비교 모듈**로 넘어갑니다.

### 6. 유사도 비교 모듈 (Embedding Similarity Comparison)  
임베딩 벡터가 추출되면, **유사도 비교 모듈**에서 해당 벡터와 사전에 저장된 **등록된 얼굴 임베딩 데이터베이스**를 비교하여 누구의 얼굴인지 판단합니다. 이 모듈은 주로 Raspberry Pi 5의 CPU에서 실행되는 소프트웨어 로직으로, 입력 임베딩과 DB에 저장된 여러 임베딩 간의 **거리 계산**을 수행합니다. 보통 코사인 유사도 또는 유클리드 거리 공식을 사용하여 벡터 간 유사도를 측정하며, 가장 가까운 벡터의 ID를 찾아냅니다. 예를 들어 **코사인 유사도**가 0.8 이상이면 동일 인물로 간주하거나, 유클리드 거리가 특정 임계값 이하로 가장 작게 나오는 DB 벡터의 사람으로 인식하는 식입니다. 만약 어느 임베딩과도 유사도가 충분히 높지 않으면 “Unknown (미등록 인물)”로 분류할 수 있습니다. 유사도 비교 연산 자체는 매우 빠르며 (벡터 내 곱셈-덧셈 연산), 수백~수천 명 규모의 임베딩 DB도 Raspberry Pi 5가 실시간으로 처리 가능합니다. 이 단계에서는 또한 **추적 및 갱신** 로직이 포함될 수 있는데, 연속된 프레임에서 동일한 ID로 인식된 경우 하나의 **추적 ID**로 묶어주거나, 인식 결과의 신뢰도를 계산하여 출력할 지 여부를 결정하는 등의 작업을 합니다. 최종적으로 현재 프레임의 각 얼굴에 대한 신원 인식 결과(또는 미인식 상태)가 결정되며, 다음 출력 모듈로 전달됩니다.

### 7. 결과 출력 (Result Output)  
**결과 출력 모듈**은 인식된 얼굴에 대한 **최종 정보**를 사용자나 다른 시스템에 전달하는 역할을 합니다. 실시간 얼굴 인식 시스템에서는 주로 **영상 위에 인식 결과를 오버레이**하여 출력하거나, 인식된 인물의 ID를 외부 시스템으로 전달합니다. 예를 들어, GStreamer 파이프라인의 마지막 단계에 **OSD(On-Screen Display)** 요소나 어플리케이션 레벨에서 **텍스트/그래픽 오버레이**를 사용하여, 영상 내 얼굴 위치마다 **이름 태그**나 **인식 점수**를 그려넣을 수 있습니다. Raspberry Pi 5의 디스플레이 출력(PWM 또는 HDMI)에 영상을 띄워 모니터에 보여주거나, 웹 대시보드로 스트리밍할 수도 있습니다. 만약 물리적인 화면 출력이 없고 단순 출입 통제 시스템이라면, **인식된 ID를 소프트웨어 신호로 전송**하여 문을 여는 등의 액션을 취하게 할 수도 있습니다. 어떤 방식이든, 이 모듈은 **이전 단계에서 결정된 얼굴 인식 결과를 사람이 이해할 수 있는 형태로 제공**하는 것을 목표로 합니다. 출력 형식에는 인물의 이름, 고유 ID, 혹은 “미등록 사용자” 등의 라벨이 포함되며, 필요 시 시간 기록이나 위치 정보와 함께 로그를 남겨 보관할 수도 있습니다. 결과 출력은 지연이 거의 없이 실시간으로 이루어져야 하므로, 이전 모듈들의 처리 완료 신호를 받아 즉각 수행되며 파이프라인이 다음 프레임 처리를 이어나갈 수 있도록 비동기적으로 동작합니다.

## 실시간 데이터 흐름과 시스템 상호 작용 (Data Flow & Real-time Operation)  
이 섹션에서는 앞서 설명한 모듈들이 **실시간으로 상호 연동**되는 과정을 단계별로 정리합니다. 시스템은 1초에 수십장의 프레임을 처리해야 하므로, 각 구성 요소가 파이프라인 형태로 **스트림 데이터**를 처리하고 병렬로 동작하여 전체 지연을 최소화합니다. 실시간 엣지 AI 동작의 핵심은 **파이프라인 처리**와 **하드웨어 가속의 효율적 분배**이며, Raspberry Pi 5의 CPU와 Hailo-8 AI 가속기가 긴밀히 협력합니다. 아래는 한 프레임에 대한 처리 흐름을 순서대로 나타낸 것입니다:

1. **카메라 캡처:** 카메라 모듈이 현재 시각의 프레임을 촬영하여 버퍼에 저장합니다. GStreamer 파이프라인의 `src`(source) 요소가 이 프레임을 받아옵니다.  
2. **프레임 전처리:** 해당 프레임은 GStreamer 내에서 색상 포맷 변환(YUV→RGB)과 해상도 조정 등의 전처리를 거칩니다. 필요한 경우 영상의 크기를 딥러닝 모델 입력 크기에 맞게 리사이즈하고, 배치(batch) 차원을 추가하여 추론 요청을 준비합니다.  
3. **얼굴 검출 추론:** 전처리된 프레임 데이터가 **Hailo-8** 가속기로 전달되어 얼굴 검출 신경망의 입력으로 들어갑니다. HailoRT 런타임이 이 작업을 관리하며, Hailo-8은 수 ms 내에 얼굴 위치와 크기를 예측합니다. 한 프레임 내 여러 얼굴이 있을 경우 **모든 얼굴의 바운딩 박스 좌표 리스트**를 출력합니다.  
4. **랜드마크 추출 및 얼굴 정렬:** 검출 결과 중 각 얼굴 ROI는 CPU 메모리로 복사되거나 Hailo-8 상에서 바로 **두 번째 추론 입력**으로 사용됩니다. 두 번째 모델(얼굴 랜드마크 검출)이 Hailo-8에서 실행되어 각 얼굴의 특징 점(예: 두 눈, 코, 입 위치)을 산출합니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Facial%20detection%20is%20a%20common,orientation%2C%20structure%20and%20so%20on)). Raspberry Pi 5 CPU는 이 랜드마크들을 이용해 ROI 영상을 회전/이동시켜 얼굴을 정규 방향으로 맞춥니다. 이 단계는 여러 얼굴에 대해서 **반복**되며, 결과적으로 각 얼굴마다 인식에 최적화된 정면 정렬 이미지가 생성됩니다.  
5. **임베딩 벡터 추출:** 정렬된 얼굴 이미지들이 다시 한번 Hailo-8으로 보내져 **얼굴 인식 임베딩** 신경망의 입력으로 처리됩니다. Hailo-8은 각 얼굴마다 고유한 임베딩 벡터를 산출하여 반환하고, Raspberry Pi 5는 이를 수신합니다. 예를 들어 128-D의 부동소수점 임베딩이 출력됩니다. 이 과정에서 Hailo-8은 다중 얼굴에 대한 추론을 연속적으로 빠르게 실행할 수 있으며, GPU나 CPU보다 훨씬 낮은 지연으로 결과를 제공합니다.  
6. **임베딩 비교 및 신원 확인:** 하나의 프레임 내 모든 얼굴에 대한 임베딩 벡터들이 준비되면, Raspberry Pi 5의 CPU가 이를 사전에 저장된 **등록 임베딩 DB**와 비교합니다. 각 벡터마다 DB 내 가장 **유사한 임베딩 항목**을 찾고 임계값을 적용하여 동일인 여부를 확인합니다. 이 때 CPU는 벡터 연산과 간단한 루프만 수행하므로, 병렬로 여러 얼굴을 처리해도 수 밀리초 이내에 모든 비교가 완료됩니다. 비교 결과로 각 얼굴에 대응되는 **신원 ID 혹은 Unknown** 결정이 이루어집니다.  
7. **결과 통합 및 출력:** 마지막으로, 현재 프레임에 대한 모든 얼굴의 인식 결과를 모아 출력 단계로 넘깁니다. GStreamer 파이프라인의 최종 출력 요소(예: `appsink` 또는 디스플레이 출력)에 프레임을 전달하기 전에, **CPU가 해당 프레임에 대한 후처리**를 수행합니다. 후처리에는 검출된 얼굴 위치에 사각형 경계선 그리기, ID 레이블 문자열 렌더링 등이 포함됩니다. 그런 다음, GStreamer의 싱크(sink) 요소가 **화면**에 영상 프레임을 표시하거나, 결과 데이터를 MQTT/HTTP 등을 통해 외부로 송신할 수 있습니다. 사용자는 모니터를 통해 실시간으로 **얼굴에 이름이 붙은 영상**을 확인할 수 있으며, 전체 과정은 매 프레임(33ms 내외)마다 파이프라인을 통해 지속적으로 반복됩니다.

이러한 흐름에서 각 모듈은 **스트림 데이터 처리** 방식으로 동작하여 병목 현상을 최소화합니다. 예를 들어, Hailo-8에서 얼굴 임베딩을 추론하는 동안(Raspberry Pi 5에서는 거의 부담이 없는 동안) CPU는 이전 프레임의 임베딩 비교를 수행하거나 다음 프레임 준비를 할 수 있습니다. GStreamer는 내부적으로 프레임별 **버퍼링과 동기화**를 관리하므로, 약간의 파이프라인 지연만으로 지속적인 실시간 처리가 가능합니다. 결과적으로 Raspberry Pi 5 + Hailo-8 조합은 **카메라 → 추론 → 출력**까지 수십 밀리초대의 지연으로 얼굴 인식을 수행하며, 한 대의 소형 엣지 디바이스에서 **실시간 얼굴 식별**이 이루어집니다.

**요약:** 본 시스템 아키텍처는 카메라, GStreamer 파이프라인, Hailo TAPPAS 기반 얼굴 검출 및 인식, 임베딩 매칭, 결과 출력의 각 구성요소가 유기적으로 연동되어 동작합니다. Hailo-8 가속기는 **딥러닝 추론 부하**를 전담하여 Raspberry Pi 5가 처리해야 할 연산을 크게 줄여주며, GStreamer와 TAPPAS 소프트웨어 프레임워크는 이러한 하드웨어를 효율적으로 활용할 수 있는 **표준 파이프라인**을 제공합니다 ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Hailo%20has%20developed%20TAPPAS%20to,friendly)) ([Software Suite for AI Applications & Deep Learning | Hailo AI](https://hailo.ai/products/hailo-software/hailo-ai-software-suite/#sw-tappas#:~:text=Explorer%20offers%20an%20interactive%20interface,models%20from%20Hailo%E2%80%99s%20vast%20library)). 그 결과, 본 엣지 AI 시스템은 인터넷 연결이나 클라우드 없이도 현장에서 즉각적으로 얼굴을 인식하고 대응할 수 있는 **실시간 성능과 정확도**를 갖추게 됩니다.
